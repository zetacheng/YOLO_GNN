import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import knn_graph, SAGEConv, TopKPooling
from vig_module import ViG
from dim_manager import Dim_Manager # âœ… å¼•å…¥ç¶­åº¦ç®¡ç†

class ViG_GNN(nn.Module):
    def __init__(self, num_classes):
        super(ViG_GNN, self).__init__()
        self.dim_manager = Dim_Manager()  # âœ… ä½¿ç”¨çµ±ä¸€ç¶­åº¦ç®¡ç†
        ViG_feature_dim = self.dim_manager.enquireDimValue("ViG_feature_dim")
        gnn1_input_dim = self.dim_manager.enquireDimValue("GNN1_Input")
        gnn1_output_dim = self.dim_manager.enquireDimValue("GNN1_Output")
#        gnn2_input_dim = self.dim_manager.enquireDimValue("GNN2_Input")
#        gnn2_output_dim = self.dim_manager.enquireDimValue("GNN2_Output")
        self.knn_neighbors = self.dim_manager.enquireDimValue("knn_neighbors")
        self.batch_size = self.dim_manager.meta.batch_size  # âœ… **æ­£ç¢ºç²å– batch_size**
        
        # **è¨­å®š Pooling Ratio**
        self.pool_ratio = 0.75  # âœ… èª¿æ•´ Pooling æ¯”ä¾‹ï¼Œç¢ºä¿ç¯€é»æ•¸æ¸›å°‘æ™‚ä»æœ‰è¶³å¤ è¨Šæ¯

         # âœ… ç¢ºä¿ ViG è¼¸å‡ºç¶­åº¦èˆ‡ GNN1 çš„è¼¸å…¥ç¶­åº¦ä¸€è‡´
        assert ViG_feature_dim == gnn1_input_dim, "âŒ ViG è¼¸å‡ºç¶­åº¦èˆ‡ GNN1 ä¸åŒ¹é…ï¼"       

        self.vig = ViG() # âœ… ViG å±€éƒ¨å­¸ç¿’
        self.gnn1 = SAGEConv(gnn1_input_dim, gnn1_output_dim)  # âœ… Pooling 1 å‰çš„ GNN
        self.pool1 = TopKPooling(gnn1_output_dim, ratio=self.pool_ratio)  # âœ… ç¬¬ä¸€æ¬¡ Pooling

#        self.gnn2 = SAGEConv(gnn2_input_dim, gnn2_output_dim)  # âœ… Pooling 2 å‰çš„ GNN
#        self.pool2 = TopKPooling(gnn2_output_dim, ratio=self.pool_ratio)  # âœ… ç¬¬äºŒæ¬¡ Pooling
        
        # âœ… åˆå§‹åŒ– `final_gnn`ï¼Œç¨å¾Œå¯èƒ½æœƒå‹•æ…‹èª¿æ•´
#        self.final_gnn = SAGEConv(gnn2_output_dim, num_classes)
        self.final_gnn = SAGEConv(gnn1_output_dim, num_classes)

    def forward(self, x):
        # 1ï¸âƒ£ ViG è¼¸å‡ºå±€éƒ¨åœ–çµæ§‹
        features, edge_index = self.vig(x)
        #print(f"ğŸ” [DEBUG] ViG Output: Features Shape: {features.shape}, Edge Index Shape: {edge_index.shape}")

        # 2ï¸âƒ£ GNN1 æå–ç‰¹å¾µ
        features = self.gnn1(features, edge_index)  # âœ… å…ˆç”¨ GNN æå–ç‰¹å¾µ
        # 3ï¸âƒ£ é‡æ–°è¨ˆç®— edge_indexï¼ˆç¢ºä¿èˆ‡ GNN1 ç‰¹å¾µå°æ‡‰ï¼‰
        edge_index = knn_graph(features, k=min(self.knn_neighbors, features.shape[0] - 1), loop=True)

        # 4ï¸âƒ£ Top-K Poolingï¼ˆç¬¬ä¸€å±¤ï¼‰
        features, edge_index, _, batch, _, _ = self.pool1(features, edge_index)
        batch_size_1 = batch.unique().size(0)  # âœ… **æ­£ç¢ºè¨ˆç®— batch_size**
        #print(f"ğŸ” [DEBUG] After Pooling 1: Features Shape: {features.shape}, Edge Index Shape: {edge_index.shape}")
        #print(f"ğŸ” [DEBUG] Batch Size 1: {batch_size_1}")
       # **ç•¶ batch_size_1 å¤ªå°æ™‚ï¼Œç›´æ¥è½‰ç‚ºå…¨é€£æ¥**
#        if batch_size_1 < self.knn_neighbors:
#            print(f"âš ï¸ Warning: batch_size_1 ({batch_size_1}) å¤ªå°ï¼Œæ”¹ç‚ºå…¨é€£æ¥")
#            edge_index = torch.combinations(torch.arange(features.shape[0]), r=2).T.to(features.device)
#        else:
        edge_index = knn_graph(features, k=min(self.knn_neighbors, features.shape[0] - 1), loop=True)

#        # 4ï¸âƒ£ Top-K Poolingï¼ˆç¬¬äºŒå±¤ï¼‰
#        features = self.gnn2(features, edge_index)  # âœ… å†ç”¨ GNN æå–ç‰¹å¾µ
#        features, edge_index, _, batch, _, _ = self.pool2(features, edge_index)
#        batch_size_2 = batch.unique().size(0)  # âœ… **æ­£ç¢ºè¨ˆç®— batch_size**
#        print(f"ğŸ” [DEBUG] After Pooling 2: Features Shape: {features.shape}, Edge Index Shape: {edge_index.shape}")

#       # **ç•¶ batch_size_2 å¤ªå°æ™‚ï¼Œç›´æ¥è½‰ç‚ºå…¨é€£æ¥**
#        if batch_size_2 < self.knn_neighbors:
#            print(f"âš ï¸ Warning: batch_size_2 ({batch_size_2}) å¤ªå°ï¼Œæ”¹ç‚ºå…¨é€£æ¥")
#            edge_index = torch.combinations(torch.arange(features.shape[0]), r=2).T.to(features.device)
#        else:
#        edge_index = knn_graph(features, k=min(self.knn_neighbors, features.shape[0] - 1), loop=True)

        # 5ï¸âƒ£ æœ€çµ‚ GraphSAGE é€²è¡Œå…¨é€£æ¥åˆ†é¡
        # âœ… **å‹•æ…‹èª¿æ•´ final GNN**
        final_gnn_input_dim = features.shape[1]  # **å–æœ€å¾Œ GNN çš„è¼¸å‡ºç¶­åº¦**
        if self.final_gnn.in_channels != final_gnn_input_dim:
            print(f"âš ï¸ Warning: Adjusting final GNN input_dim to {final_gnn_input_dim}")
            self.final_gnn = SAGEConv(final_gnn_input_dim, self.dim_manager.meta.vig_num_classes).to(features.device)

        # âœ… **ç¢ºä¿ batch_size èˆ‡ target batch_size ä¸€è‡´**
        if features.shape[0] != self.batch_size:
            print(f"âš ï¸ Warning: Adjusting final batch_size from {features.shape[0]} to {self.batch_size}")
            features = features[:self.batch_size]

        # 5ï¸âƒ£ æœ€çµ‚ GraphSAGE é€²è¡Œå…¨é€£æ¥åˆ†é¡
        final_output = self.final_gnn(features, edge_index)
        print(f"ğŸ” [DEBUG] Final Output Shape: {final_output.shape}")

        return final_output
